# ğŸ âš¡ Home Energy Management System

Sistema de gerenciamento de energia residencial baseado em microsserviÃ§os, desenvolvido com Spring Boot, Kafka e MySQL. O sistema permite monitoramento em tempo real do consumo energÃ©tico de dispositivos IoT domÃ©sticos.

---

## ğŸ“‹ SumÃ¡rio

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [Executando o Projeto](#-executando-o-projeto)
- [API Endpoints](#-api-endpoints)
- [SimulaÃ§Ã£o de Dados](#-simulaÃ§Ã£o-de-dados)
- [Estrutura do Banco de Dados](#-estrutura-do-banco-de-dados)
- [Monitoramento](#-monitoramento)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O **Home Energy Management System** Ã© uma soluÃ§Ã£o completa para monitoramento e anÃ¡lise de consumo energÃ©tico em ambientes residenciais. O sistema Ã© composto por trÃªs microsserviÃ§os principais:

### MicrosserviÃ§os

1. **User Service** (Porta 8080)
   - Gerenciamento de usuÃ¡rios
   - ConfiguraÃ§Ã£o de alertas de consumo
   - DefiniÃ§Ã£o de thresholds energÃ©ticos

2. **Device Service** (Porta 8081)
   - CRUD de dispositivos IoT
   - Suporte para mÃºltiplos tipos: SPEAKER, CAMERA, THERMOSTAT, LOCK, LIGHT, DOORBELL
   - AssociaÃ§Ã£o de dispositivos com usuÃ¡rios

3. **Ingestion Service** (Porta 8082)
   - IngestÃ£o de dados de consumo energÃ©tico
   - PublicaÃ§Ã£o de eventos no Kafka
   - Simuladores de carga (sequencial e paralelo)

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Service   â”‚      â”‚ Device Service  â”‚      â”‚Ingestion Serviceâ”‚
â”‚   (Port 8080)   â”‚      â”‚   (Port 8081)   â”‚      â”‚   (Port 8082)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      MySQL Database       â”‚
                    â”‚       (Port 3307)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                                   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  Kafka   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Zookeeper â”‚
    â”‚(Port 9092)â”‚                                      â”‚(Port 2181)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Kafka UI â”‚
    â”‚(Port 8070)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. Dispositivos enviam dados de consumo â†’ **Ingestion Service**
2. Ingestion Service publica eventos â†’ **Kafka Topic** (`energy-usage`)
3. Eventos sÃ£o consumidos por processadores downstream (futuro)
4. Dados persistidos no **MySQL** via Flyway migrations

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **Java 21** (Eclipse Temurin)
- **Spring Boot 3.x**
  - Spring Web
  - Spring Data JPA
  - Spring Kafka
  - Spring AOP (Logging e Performance)
- **Lombok** (ReduÃ§Ã£o de boilerplate)

### Infraestrutura
- **MySQL 8.0.44** (Banco de dados relacional)
- **Apache Kafka 7.6.0** (Message broker)
- **Zookeeper 3.8** (CoordenaÃ§Ã£o do Kafka)
- **Kafka UI** (Interface de gerenciamento)
- **Docker & Docker Compose** (ContainerizaÃ§Ã£o)

### Ferramentas
- **Flyway** (MigraÃ§Ãµes de banco de dados)
- **HikariCP** (Connection pooling)
- **AspectJ** (AOP para logging)

---

## âœ… PrÃ©-requisitos

- **Docker** 20.10+ e **Docker Compose** 1.29+
- **Java 21** (para desenvolvimento local)
- **Maven 3.8+** (para build)
- **Git**
- **4GB RAM** disponÃ­vel (mÃ­nimo recomendado)

### VerificaÃ§Ã£o de VersÃµes

```bash
docker --version
docker-compose --version
java -version
mvn -version
```

---

## ğŸ“¦ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone <repository-url>
cd home-energy-management
```

### 2. Estrutura do Projeto

```
home-energy-management/
â”œâ”€â”€ user-service/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ device-service/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ ingestion-service/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ init.sql
```

### 3. ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente

Crie/edite o arquivo `.env`:

```env
MYSQL_ROOT_PASSWORD=rootpassword
MYSQL_DATABASE=energy_db
MYSQL_USER=energy_user
MYSQL_PASSWORD=energy123
```

### 4. Build dos ServiÃ§os

#### OpÃ§Ã£o A: Build Individual (Maven)

```bash
# User Service
cd user-service
mvn clean package -DskipTests
cd ..

# Device Service
cd device-service
mvn clean package -DskipTests
cd ..

# Ingestion Service
cd ingestion-service
mvn clean package -DskipTests
cd ..
```

#### OpÃ§Ã£o B: Build via Docker Compose

```bash
docker-compose build
```

---

## ğŸš€ Executando o Projeto

### Iniciar Todos os ServiÃ§os

```bash
docker-compose up -d
```

### Verificar Status dos Containers

```bash
docker-compose ps
```

SaÃ­da esperada:
```
NAME                    STATUS              PORTS
mysql-home-energy       Up (healthy)        0.0.0.0:3307->3306/tcp
zookeeper-home-energy   Up                  0.0.0.0:2181->2181/tcp
kafka-home-energy       Up                  0.0.0.0:9092->9092/tcp
kafka-ui-home-energy    Up                  0.0.0.0:8070->8080/tcp
ingestion-service       Up                  0.0.0.0:8082->8082/tcp
```

### Logs dos ServiÃ§os

```bash
# Todos os serviÃ§os
docker-compose logs -f

# ServiÃ§o especÃ­fico
docker-compose logs -f ingestion-service
docker-compose logs -f kafka
```

### Parar os ServiÃ§os

```bash
docker-compose down

# Com remoÃ§Ã£o de volumes (dados serÃ£o perdidos)
docker-compose down -v
```

---

## ğŸ“¡ API Endpoints

### User Service (http://localhost:8080)

#### Criar UsuÃ¡rio
```bash
POST /api/v1/user
Content-Type: application/json

{
  "name": "JoÃ£o",
  "surname": "Silva",
  "email": "joao@email.com",
  "address": "Rua A, 123",
  "alerting": true,
  "energyAlertingThreshold": 100.0
}
```

#### Buscar UsuÃ¡rio
```bash
GET /api/v1/user/{id}
```

#### Atualizar UsuÃ¡rio
```bash
PUT /api/v1/user
Content-Type: application/json

{
  "id": 1,
  "name": "JoÃ£o",
  "surname": "Silva Santos",
  "email": "joao.novo@email.com",
  "address": "Rua B, 456",
  "alerting": false,
  "energyAlertingThreshold": 150.0
}
```

#### Deletar UsuÃ¡rio
```bash
DELETE /api/v1/user/{id}
```

---

### Device Service (http://localhost:8081)

#### Criar Dispositivo
```bash
POST /api/v1/device/create
Content-Type: application/json

{
  "name": "Smart Lamp Sala",
  "type": "LIGHT",
  "location": "Sala de Estar",
  "userId": 1
}
```

**Tipos de dispositivos suportados:**
- `SPEAKER`
- `CAMERA`
- `THERMOSTAT`
- `LOCK`
- `LIGHT`
- `DOORBELL`

#### Buscar Dispositivo
```bash
GET /api/v1/device/{id}
```

#### Atualizar Dispositivo
```bash
PUT /api/v1/device/{id}
Content-Type: application/json

{
  "name": "Smart Lamp Quarto",
  "type": "LIGHT",
  "location": "Quarto Principal",
  "userId": 1
}
```

#### Deletar Dispositivo
```bash
DELETE /api/v1/device/{id}
```

---

### Ingestion Service (http://localhost:8082)

#### Ingerir Dados de Consumo
```bash
POST /api/v1/ingestion
Content-Type: application/json

{
  "deviceId": 1,
  "energyConsumed": 1.45,
  "timestamp": "2025-12-11T14:30:00Z"
}
```

**Resposta:** `201 Created` (sem corpo)

---

## ğŸ² SimulaÃ§Ã£o de Dados

O **Ingestion Service** possui dois simuladores de carga integrados:

### 1. Simulador ContÃ­nuo (ContinuosDataSimulator)

- **DescriÃ§Ã£o:** Envia requisiÃ§Ãµes sequenciais em intervalos fixos
- **ConfiguraÃ§Ã£o:** `application.properties`

```properties
simulation.request-internal=3
simulation.interval-ms=5000
simulation.ingestion-endpoint=http://localhost:8082/api/v1/ingestion
```

**Comportamento:**
- Envia 3 requisiÃ§Ãµes a cada 5 segundos
- Dispositivos aleatÃ³rios (ID 1-5)
- Consumo entre 0.0 e 2.0 kWh

---

### 2. Simulador Paralelo (ParallelDataSimulation)

- **DescriÃ§Ã£o:** Envia requisiÃ§Ãµes paralelas usando thread pool
- **ConfiguraÃ§Ã£o:** `application.properties`

```properties
simulation.parallel-threads=10
simulation.requests-per-interval=5000
simulation.endpoint=http://localhost:8082/api/v1/ingestion
simulation.execution-interval-ms=5000
```

**Comportamento:**
- 10 threads paralelas
- 5000 requisiÃ§Ãµes por execuÃ§Ã£o (500 por thread)
- Executa a cada 5 segundos
- Dispositivos aleatÃ³rios (ID 1-1000)
- Consumo entre 0.1 e 5.0 kWh

**âš ï¸ AtenÃ§Ã£o:** O simulador paralelo gera **carga significativa**. Ajuste os parÃ¢metros conforme capacidade do sistema.

---

### Desabilitar Simuladores

Para desabilitar, comente a anotaÃ§Ã£o `@Component`:

```java
// @Component
@Slf4j
public class ParallelDataSimulation implements CommandLineRunner {
    // ...
}
```

---

## ğŸ—„ï¸ Estrutura do Banco de Dados

### Tabela: `user`

| Coluna                     | Tipo         | DescriÃ§Ã£o                          |
|----------------------------|--------------|------------------------------------|
| id                         | BIGINT       | PK, Auto Increment                 |
| name                       | VARCHAR(100) | Nome do usuÃ¡rio                    |
| surname                    | VARCHAR(255) | Sobrenome                          |
| email                      | VARCHAR(255) | Email Ãºnico                        |
| address                    | TEXT         | EndereÃ§o residencial               |
| alerting                   | TINYINT(1)   | Flag de alertas ativos             |
| energy_alerting_threshold  | DOUBLE       | Limite de consumo para alerta (kWh)|

**Constraints:**
- Unique Key: `uk_user_email (email)`

---

### Tabela: `device`

| Coluna    | Tipo         | DescriÃ§Ã£o                          |
|-----------|--------------|------------------------------------|
| id        | BIGINT       | PK, Auto Increment                 |
| name      | VARCHAR(255) | Nome do dispositivo                |
| type      | VARCHAR(50)  | Tipo do dispositivo (enum)         |
| location  | VARCHAR(255) | LocalizaÃ§Ã£o fÃ­sica                 |
| user_id   | BIGINT       | FK para user.id                    |

**Constraints:**
- Foreign Key: `fk_device_user (user_id)` â†’ `user(id)` ON DELETE CASCADE
- Index: `idx_device_user_id (user_id)`

---

### MigraÃ§Ãµes Flyway

Localizadas em: `src/main/resources/db/migration/`

```
V1__create_user_table.sql
V2__create_device_table.sql
```

**AplicaÃ§Ã£o automÃ¡tica:** As migraÃ§Ãµes sÃ£o executadas na inicializaÃ§Ã£o dos serviÃ§os.

---

## ğŸ“Š Monitoramento

### Kafka UI

Acesse: **http://localhost:8070**

**Recursos:**
- VisualizaÃ§Ã£o de tÃ³picos e mensagens
- Monitoramento de consumer groups
- InspeÃ§Ã£o de offsets
- EstatÃ­sticas de throughput

**TÃ³pico principal:** `energy-usage`

---

### Logs de Performance (AOP)

O **User Service** possui aspectos para logging automÃ¡tico:

#### ExecutionTimeAspect
Registra tempo de execuÃ§Ã£o dos controllers:

```
Controller method UserController.createUser(..) executed in 145 ms
```

#### LoggingAspect
Registra entrada/saÃ­da dos mÃ©todos de serviÃ§o:

```
â†’ Calling service method: UserService.createUser(..) with arguments: [UserDto(...)]
â† Service method: UserService.createUser(..) returned: UserDto(id=1, ...)
âœ— Service method: UserService.getUserById(..) threw exception: User not found
```

---

### Healthcheck do MySQL

```bash
docker exec mysql-home-energy mysqladmin ping -h localhost -u root -prootpassword
```

Resposta esperada: `mysqld is alive`

---

### Verificar Conectividade do Kafka

```bash
# Listar tÃ³picos
docker exec kafka-home-energy kafka-topics --list --bootstrap-server localhost:29092

# Descrever tÃ³pico
docker exec kafka-home-energy kafka-topics --describe --topic energy-usage --bootstrap-server localhost:29092
```

---

## ğŸ”§ Troubleshooting

### Problema: Container do Kafka nÃ£o inicia

**Sintoma:**
```
kafka-home-energy | Error: Network is unreachable
```

**SoluÃ§Ã£o:**
1. Verifique o IP do host no `docker-compose.yml`:
```yaml
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://192.168.1.89:9092
```

2. Substitua `192.168.1.89` pelo IP da sua mÃ¡quina:
```bash
ip addr show | grep "inet 192"
```

3. Reinicie os containers:
```bash
docker-compose down
docker-compose up -d
```

---

### Problema: MigraÃ§Ãµes Flyway falham

**Sintoma:**
```
FlywayException: Validate failed: Migration checksum mismatch
```

**SoluÃ§Ã£o:**
1. Limpar histÃ³rico do Flyway:
```sql
DELETE FROM flyway_schema_history;
```

2. Recriar banco de dados:
```bash
docker-compose down -v
docker-compose up -d db
```

3. Reiniciar serviÃ§os:
```bash
docker-compose up -d
```

---

### Problema: "Too many connections" no MySQL

**Sintoma:**
```
SQLNonTransientConnectionException: Too many connections
```

**SoluÃ§Ã£o:**
1. Ajustar pool de conexÃµes no `application.properties`:
```properties
spring.datasource.hikari.maximum-pool-size=5
spring.datasource.hikari.minimum-idle=2
```

2. Aumentar limite do MySQL (temporÃ¡rio):
```sql
SET GLOBAL max_connections = 200;
```

---

### Problema: Ingestion Service nÃ£o publica no Kafka

**Sintoma:**
```
KafkaException: Failed to send message
```

**VerificaÃ§Ãµes:**
1. Confirmar que Kafka estÃ¡ rodando:
```bash
docker-compose ps kafka
```

2. Testar conectividade:
```bash
telnet localhost 9092
```

3. Verificar logs do Kafka:
```bash
docker-compose logs kafka | grep ERROR
```

4. Validar configuraÃ§Ã£o do bootstrap server:
```properties
spring.kafka.bootstrap-servers=192.168.1.89:9092
```

---

### Problema: Porta jÃ¡ em uso

**Sintoma:**
```
Error starting userland proxy: listen tcp 0.0.0.0:8080: bind: address already in use
```

**SoluÃ§Ã£o:**
1. Identificar processo:
```bash
lsof -i :8080
```

2. Matar processo:
```bash
kill -9 <PID>
```

3. Ou alterar porta no `application.properties`:
```properties
server.port=8090
```

---

## ğŸ” SeguranÃ§a

### ConsideraÃ§Ãµes de ProduÃ§Ã£o

âš ï¸ **Este projeto Ã© para fins educacionais/desenvolvimento.** Para produÃ§Ã£o, considere:

1. **AutenticaÃ§Ã£o/AutorizaÃ§Ã£o:**
   - Implementar Spring Security
   - OAuth2/JWT para APIs
   - Rate limiting

2. **Secrets Management:**
   - Usar variÃ¡veis de ambiente seguras
   - AWS Secrets Manager / Vault
   - Nunca comitar credenciais no cÃ³digo

3. **Network Security:**
   - TLS/SSL para comunicaÃ§Ã£o externa
   - Kafka com SASL/SCRAM
   - Firewall rules

4. **ValidaÃ§Ã£o de Entrada:**
   - Bean Validation (`@Valid`)
   - SanitizaÃ§Ã£o de inputs
   - ProteÃ§Ã£o contra SQL Injection (JPA/Hibernate jÃ¡ mitiga)

---

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] Implementar Consumer Kafka para processar eventos
- [ ] Adicionar agregaÃ§Ã£o de dados por perÃ­odo (hourly/daily)
- [ ] Dashboard de visualizaÃ§Ã£o (Grafana)
- [ ] NotificaÃ§Ãµes em tempo real (WebSocket)
- [ ] Testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] API Gateway (Spring Cloud Gateway)
- [ ] Service Discovery (Eureka)

---

## ğŸ“ LicenÃ§a

Este projeto Ã© open source e estÃ¡ disponÃ­vel sob a [MIT License](LICENSE).

---

## ğŸ‘¥ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch de feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

****
